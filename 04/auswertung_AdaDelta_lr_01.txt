-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer AdaDelta, Learning Rate 0.1, Batch Size 1
Epoch 0
loss ->  0.14376340806484222
Epoch 1
loss ->  0.10217692703008652
Epoch 2
loss ->  0.07852766662836075
Epoch 3
loss ->  0.05562124401330948
Epoch 4
loss ->  0.035576120018959045
Epoch 5
loss ->  0.03713971748948097
Epoch 6
loss ->  0.023538382723927498
Epoch 7
loss ->  0.02919856645166874
Epoch 8
loss ->  0.023521549999713898
Epoch 9
loss ->  0.02498910017311573
Test Data:
prozent 0.7876666666666666
Training Data
prozent 0.783961403508772
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer AdaDelta, Learning Rate 0.1, Batch Size 5
Epoch 0
loss ->  0.138421893119812
Epoch 1
loss ->  0.13672424852848053
Epoch 2
loss ->  0.12003272026777267
Epoch 3
loss ->  0.12324327975511551
Epoch 4
loss ->  0.12532833218574524
Epoch 5
loss ->  0.11871577054262161
Epoch 6
loss ->  0.12139110267162323
Epoch 7
loss ->  0.11981350183486938
Epoch 8
loss ->  0.11669807136058807
Epoch 9
loss ->  0.10236039012670517
Test Data:
prozent 0.429
Training Data
prozent 0.4437894736842105
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer AdaDelta, Learning Rate 0.1, Batch Size 10
Epoch 0
loss ->  0.1319728046655655
Epoch 1
loss ->  0.13283443450927734
Epoch 2
loss ->  0.12726029753684998
Epoch 3
loss ->  0.1312199831008911
Epoch 4
loss ->  0.12088803201913834
Epoch 5
loss ->  0.1353338658809662
Epoch 6
loss ->  0.1317012757062912
Epoch 7
loss ->  0.1275777518749237
Epoch 8
loss ->  0.12699666619300842
Epoch 9
loss ->  0.1252935528755188
Test Data:
prozent 0.266
Training Data
prozent 0.2749824561403509
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer AdaDelta, Learning Rate 0.1, Batch Size 50
Epoch 0
loss ->  0.19026896357536316
Epoch 1
loss ->  0.1541302651166916
Epoch 2
loss ->  0.13885240256786346
Epoch 3
loss ->  0.1320808380842209
Epoch 4
loss ->  0.13356655836105347
Epoch 5
loss ->  0.12989196181297302
Epoch 6
loss ->  0.12886019051074982
Epoch 7
loss ->  0.13115288317203522
Epoch 8
loss ->  0.12968866527080536
Epoch 9
loss ->  0.13244129717350006
Test Data:
prozent 0.0
Training Data
prozent 0.0
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer AdaDelta, Learning Rate 0.1, Batch Size 100
Epoch 0
loss ->  0.23154385387897491
Epoch 1
loss ->  0.20081426203250885
Epoch 2
loss ->  0.17624539136886597
Epoch 3
loss ->  0.15942996740341187
Epoch 4
loss ->  0.14754046499729156
Epoch 5
loss ->  0.14173907041549683
Epoch 6
loss ->  0.13758569955825806
Epoch 7
loss ->  0.13682091236114502
Epoch 8
loss ->  0.13380903005599976
Epoch 9
loss ->  0.13396720588207245
Test Data:
prozent 0.0
Training Data
prozent 0.0
****************************************************************************************************
