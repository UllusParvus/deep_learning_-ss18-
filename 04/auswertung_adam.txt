-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer Adam, Learning Rate 0.0001, Batch Size 1
Epoch 0
loss ->  0.1061074286699295
Epoch 1
loss ->  0.049891095608472824
Epoch 2
loss ->  0.02901786006987095
Epoch 3
loss ->  0.022845333442091942
Epoch 4
loss ->  0.016375627368688583
Epoch 5
loss ->  0.014740045182406902
Epoch 6
loss ->  0.02765641361474991
Epoch 7
loss ->  0.026733970269560814
Epoch 8
loss ->  0.014793897978961468
Epoch 9
loss ->  0.018961617723107338
Test Data:
prozent 0.7963333333333333
Training Data
prozent 0.7927754385964912
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer Adam, Learning Rate 0.0001, Batch Size 5
Epoch 0
loss ->  0.13530448079109192
Epoch 1
loss ->  0.13589437305927277
Epoch 2
loss ->  0.11942102015018463
Epoch 3
loss ->  0.10864788293838501
Epoch 4
loss ->  0.09186957031488419
Epoch 5
loss ->  0.06954208016395569
Epoch 6
loss ->  0.06365880370140076
Epoch 7
loss ->  0.051638804376125336
Epoch 8
loss ->  0.045512206852436066
Epoch 9
loss ->  0.042594145983457565
Test Data:
prozent 0.912
Training Data
prozent 0.9109824561403509
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer Adam, Learning Rate 0.0001, Batch Size 10
Epoch 0
loss ->  0.1875743567943573
Epoch 1
loss ->  0.15111136436462402
Epoch 2
loss ->  0.1357729434967041
Epoch 3
loss ->  0.12219686061143875
Epoch 4
loss ->  0.12241039425134659
Epoch 5
loss ->  0.11606203019618988
Epoch 6
loss ->  0.12068667262792587
Epoch 7
loss ->  0.10391092300415039
Epoch 8
loss ->  0.10161294043064117
Epoch 9
loss ->  0.08917664736509323
Test Data:
prozent 0.5613333333333334
Training Data
prozent 0.5622456140350878
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer Adam, Learning Rate 0.0001, Batch Size 50
Epoch 0
loss ->  0.2350047379732132
Epoch 1
loss ->  0.2162255346775055
Epoch 2
loss ->  0.19887356460094452
Epoch 3
loss ->  0.18613745272159576
Epoch 4
loss ->  0.17361792922019958
Epoch 5
loss ->  0.16496022045612335
Epoch 6
loss ->  0.1568726897239685
Epoch 7
loss ->  0.15087449550628662
Epoch 8
loss ->  0.14678828418254852
Epoch 9
loss ->  0.14469397068023682
Test Data:
prozent 0.05
Training Data
prozent 0.022280701754385963
****************************************************************************************************
-|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|--|-
Optimizer Adam, Learning Rate 0.0001, Batch Size 100
Epoch 0
loss ->  0.2174365222454071
Epoch 1
loss ->  0.20895642042160034
Epoch 2
loss ->  0.2010193020105362
Epoch 3
loss ->  0.19356434047222137
Epoch 4
loss ->  0.18770506978034973
Epoch 5
loss ->  0.18000534176826477
Epoch 6
loss ->  0.17243555188179016
Epoch 7
loss ->  0.16685892641544342
Epoch 8
loss ->  0.16053366661071777
Epoch 9
loss ->  0.15622200071811676
Test Data:
prozent 0.0
Training Data
prozent 0.0
****************************************************************************************************
